{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             feature       class_label\n",
      "0  [[-306.77255, -177.59209, -99.13616, -65.97198...          dog_bark\n",
      "1  [[-457.69534, -451.0248, -450.68613, -445.0000...  children_playing\n",
      "2  [[-323.20044, -244.39201, -208.50298, -184.233...          car_horn\n",
      "3  [[-688.7444, -262.64093, -105.28191, -60.13772...   air_conditioner\n",
      "4  [[-205.19269, -215.90787, -209.7127, -184.8985...      street_music\n",
      "5  [[-119.95263, -98.58099, -102.46894, -113.9573...          gun_shot\n",
      "6  [[-212.37454, -203.63791, -200.84283, -208.838...             siren\n",
      "7  [[-168.26811, -159.26343, -158.1763, -156.5134...     engine_idling\n",
      "8  [[-298.7493, -288.96646, -294.43912, -300.8143...        jackhammer\n",
      "9  [[-686.07166, -615.6793, -523.6804, -469.46082...          drilling\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load features\n",
    "featuresdf = pd.read_pickle('featuresData')\n",
    "print(featuresdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y)) \n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Neural Network (CNN) model architecture\n",
    "\n",
    "#We will modify our model to be a Convolutional Neural Network (CNN) again using Keras and a Tensorflow backend.\n",
    "\n",
    "#Again we will use a sequential model, starting with a simple model architecture, consisting of four Conv2D \n",
    "#convolution layers, with our final output layer being a dense layer.\n",
    "\n",
    "#The convolution layers are designed for feature detection. It works by sliding a filter window over the input \n",
    "#and performing a matrix multiplication and storing the result in a feature map. This operation is known as a \n",
    "#convolution.\n",
    "\n",
    "#The filter parameter specifies the number of nodes in each layer. Each layer will increase in size from 16, 32, \n",
    "#64 to 128, while the kernel_size parameter specifies the size of the kernel window which in this case is 2 \n",
    "#resulting in a 2x2 filter matrix.\n",
    "\n",
    "#The first layer will receive the input shape of (40, 174, 1) where 40 is the number of MFCC's 174 is the number \n",
    "#of frames taking padding into account and the 1 signifying that the audio is mono.\n",
    "\n",
    "#The activation function we will be using for our convolutional layers is ReLU which is the same as our previous \n",
    "#model. We will use a smaller Dropout value of 20% on our convolutional layers.\n",
    "\n",
    "#Each convolutional layer has an associated pooling layer of MaxPooling2D type with the final convolutional layer \n",
    "#having a GlobalAveragePooling2D type. The pooling layer is do reduce the dimensionality of the model (by \n",
    "#reducing the parameters and subsquent computation requirements) which serves to shorten the training time \n",
    "#and reduce overfitting. The Max Pooling type takes the maximum size for each window and the Global Average \n",
    "#Pooling type takes the average which is suitable for feeding into our dense output layer.\n",
    "\n",
    "#Our output layer will have 10 nodes (num_labels) which matches the number of possible classifications. The \n",
    "#activation is for our output layer is softmax. Softmax makes the output sum up to 1 so the output can be \n",
    "#interpreted as probabilities. The model will then make its prediction based on which option has the highest \n",
    "#probability.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_rows = 40\n",
    "num_columns = 174\n",
    "num_channels = 1\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
    "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For compiling our model, we will use the same three parameters as the previous model: \n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 39, 173, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 19, 86, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 85, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 9, 42, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 41, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 19, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4471 - accuracy: 0.0000e+00\n",
      "Pre-training accuracy: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 17.9023 - accuracy: 0.1250\n",
      "Epoch 00001: val_loss improved from inf to 3.85902, saving model to saved_models/weights.best.basic_cnn.hdf5\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 17.9023 - accuracy: 0.1250 - val_loss: 3.8590 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.2092 - accuracy: 0.0000e+00\n",
      "Epoch 00002: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.2092 - accuracy: 0.0000e+00 - val_loss: 4.3667 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0623 - accuracy: 0.1250\n",
      "Epoch 00003: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.0623 - accuracy: 0.1250 - val_loss: 4.2568 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0090 - accuracy: 0.2500\n",
      "Epoch 00004: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0090 - accuracy: 0.2500 - val_loss: 4.3639 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7802 - accuracy: 0.2500\n",
      "Epoch 00005: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.7802 - accuracy: 0.2500 - val_loss: 4.4730 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.0026 - accuracy: 0.2500\n",
      "Epoch 00006: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0026 - accuracy: 0.2500 - val_loss: 4.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7322 - accuracy: 0.2500\n",
      "Epoch 00007: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.7322 - accuracy: 0.2500 - val_loss: 4.5931 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.1420 - accuracy: 0.2500\n",
      "Epoch 00008: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1420 - accuracy: 0.2500 - val_loss: 4.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2417 - accuracy: 0.2500\n",
      "Epoch 00009: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.2417 - accuracy: 0.2500 - val_loss: 4.8019 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0435 - accuracy: 0.2500\n",
      "Epoch 00010: val_loss did not improve from 3.85902\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.0435 - accuracy: 0.2500 - val_loss: 4.9912 - val_accuracy: 0.0000e+00\n",
      "Training completed in time:  0:00:01.536192\n"
     ]
    }
   ],
   "source": [
    "#Here we will train the model. As training a CNN can take a sigificant amount of time, we will start with a \n",
    "#low number of epochs and a low batch size. If we can see from the output that the model is converging, we will \n",
    "#increase both numbers. \n",
    "\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "#num_epochs = 12\n",
    "#num_batch_size = 128\n",
    "\n",
    "#num_epochs = 72\n",
    "num_epochs = 10\n",
    "num_batch_size = 256\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_cnn.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.375\n",
      "Testing Accuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "#Here we will review the accuracy of the model on both the training and test data sets. \n",
    "\n",
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])\n",
    "\n",
    "#The Training and Testing accuracy scores are both high and an increase on our initial model. Training accuracy \n",
    "#has increased by ~6% and Testing accuracy has increased by ~4%.\n",
    "#There is a marginal increase in the difference between the Training and Test scores (~6% compared to ~5% \n",
    "#previously) though the difference remains low so the model has not suffered from overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will modify our previous method for testing the models predictions on a specified audio .wav file. \n",
    "\n",
    "import numpy as np\n",
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        \n",
    "        print(\"o\")\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        print(\"o\")\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        \n",
    "        print(mfccs.shape)\n",
    "        \n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs\n",
    "\n",
    "def print_prediction(file_name):\n",
    "    prediction_feature = extract_features(file_name) \n",
    "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n",
      "Error encountered while parsing file:  ./audio/fold3/18594-1-1-0.wav\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-79413bdb5e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./audio/fold3/18594-1-1-0.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-ebab360afcbd>\u001b[0m in \u001b[0;36mprint_prediction\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprediction_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprediction_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpredicted_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "#As before we will verify the predictions using a subsection of the sample audio files we explored in the \n",
    "#first notebook. We expect the bulk of these to be classified correctly. \n",
    "\n",
    "# Class: Air Conditioner\n",
    "\n",
    "filename = './audio/fold3/18594-1-1-0.wav' \n",
    "print_prediction(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
